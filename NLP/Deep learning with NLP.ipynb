{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent neural networks are used when a data\n",
    "pattern changes over time. RNNs can be assumed as \n",
    "unrolled over time.\n",
    "\n",
    "RNNs have feedback loops in which the output from the previous firing or time index T is fed as one of the inputs at time index T+1. There might be cases in which the output of the neuron is fed to itself as input. These are well suited for applications involving sequences.\n",
    "\n",
    "Encoding RNN- Enables network to take an input of the sequence form.\n",
    "\n",
    "Generating RNN- network basically outputs a sequence of numbers or values, like words in a sentence.\n",
    "\n",
    "General recurrent neural networks - combination of the preceding two types of RNNs. It's used to generate sequences and, thus, are widely used in NLG (natural language generation) tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoder - decoder networks\n",
    "This uses one network to create an internal representation of the input, or to 'encode' it, and that representation is used as an input for another network to produce the output.\n",
    "\n",
    "## recursive neural networks\n",
    "In a recursive neural network, a fixed set of weights is recursively applied onto the network structure and is primarily used to discover, the hierarchy or structure of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False, False, False]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "name = [1,2,3,4,5]\n",
    "name1 = [1,2.2,4,1,1]\n",
    "[np.round(i)==j for i,j in zip(name1, name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word vector representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to word Embedding\n",
    "#### Neural Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feedforward neural net language model (FNNLM) proposed by Bengio introduces a feedforward neural network consisting of a single hidden layer than prdicts the future words. \n",
    "1. Embedding layer: This keeps a record of the representation of all the words in the training dataset. It is initialized with a set of random weights. The embedding layer is made up of three parts, which includes the size of the vocabulary, the output size of the vector in which all the words will be embedded, and the length of the input sequences to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, collections, math, os, zipfile, time, re\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pylab\n",
    "%matplotlib inline\n",
    "\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "\"\"\"make sure the dataset link is copied correctly\"\"\"\n",
    "\n",
    "dataset_link = 'http://mattmahoney.net/dc/'\n",
    "zip_file = 'text8.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file downloaded successfully\n"
     ]
    }
   ],
   "source": [
    "def data_download(zip_file):\n",
    "    \"\"\"downloading the required file\"\"\"\n",
    "    if not os.path.exists(zip_file):\n",
    "        zip_file, _ = urlretrieve(dataset_link+zip_file, zip_file)\n",
    "        print(\"file downloaded successfully\")\n",
    "        \n",
    "    return None\n",
    "data_download(zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Extracting the dataset in separate folder\"\"\"\n",
    "extracted_folder = 'dataset'\n",
    "if not os.path.isdir(extracted_folder):\n",
    "    with zipfile.ZipFile(zip_file) as zf:\n",
    "        zf.extractall(extracted_folder)\n",
    "with open('dataset/text8') as ft_:\n",
    "    full_text = ft_.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(ft8_text):\n",
    "    \"\"\"Replacing punctuation marks with tokens\"\"\"\n",
    "    ft8_text = ft8_text.lower()\n",
    "    ft8_text = ft8_text.replace('.', ' <period> ')\n",
    "    ft8_text = ft8_text.replace(',', ' <comma> ')\n",
    "    ft8_text = ft8_text.replace('\"', ' <quotation> ')\n",
    "    ft8_text = ft8_text.replace(';', ' <semicolon> ')\n",
    "    ft8_text = ft8_text.replace('!', ' <exclamation> ')\n",
    "    ft8_text = ft8_text.replace('?', ' <question> ')\n",
    "    ft8_text = ft8_text.replace('(', ' <paren_l> ')\n",
    "    ft8_text = ft8_text.replace(')', ' <paren_r> ')\n",
    "    ft8_text = ft8_text.replace('--', ' <hyphen> ')\n",
    "    ft8_text = ft8_text.replace(':', ' <colon> ')\n",
    "    ft8_text_tokens = ft8_text.split()\n",
    "    return ft8_text_tokens\n",
    "\n",
    "ft_tokens = text_processing(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Shortlisting words with frequency more than 7\"\"\"\n",
    "word_cnt = collections.Counter(ft_tokens)\n",
    "shortlisted_words = [w for w in ft_tokens if word_cnt[w] > 7 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including']\n"
     ]
    }
   ],
   "source": [
    "print(shortlisted_words[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The continuous bag-of-words mode l shares an architectural similarity to the FNNLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
